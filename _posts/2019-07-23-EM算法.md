---
layout: post
title: 'EM算法理解'
subtitle: '期望最大化算法'
date: 2019-07-23
categories: 机器学习
author: Dardis
cover: '/assets/blog_img/2019-07-23-EM算法.assets/timg.jpeg'
tags: 算法 机器学习
---



参考自：

- [https://blog.csdn.net/fuqiuai/article/details/79484421](https://blog.csdn.net/fuqiuai/article/details/79484421)
- 《统计学习方法》

# 1 简介

EM算法（Expectation Maximization，期望最大化)，适用于这种情况：

> ​	你得到了一堆的数据，但是这些数据来自于不同分布，你也不知道这些数据各自是属于哪个分布，此时让你求这些分布。

因为不同于普通的根据观测值估计分布，这里的数据是多个分布的样本混合在一起，所以以前的参数估计方法有点力不从心，EM就来到了咱们的眼前。

为了理解的更方便，我们先将问题简化为一般的估计问题，也就是说所有样本都来自于同一分布，这样我们就可以用**最大似然估计**的方法求其分布。

# 2 最大似然估计

MLE（maximum likelihood estimation）最大似然估计，通过调整参数使得样本观测值的概率最大估计分布的参数（也就是说，如果我一次观测得到了值$$x$$，那么我就可以假定当前分布中取值$$x$$的概率是最大的，谁让我一观测就是他）

## 2.1 举例

参考1中有个例子，假定学校学生的身高服从正态分布，即

$$
X\sim N(\mu, \sigma^2)
$$

其中$X$是身高，$\mu, \sigma^2$是正态分布的均值和方差，他们未知，使我们要求的。此时如果我对学校学生进行随机抽样，样本数量为$$n$$，会得到$$n$$个观测值（就是随机拉来$$n$$个人，量他们的身高），记为：

$$

\{x_1, x_2, \cdots , x_n\}

$$


假设每个学生的身高互相没有影响（本来就该没有影响吧），也就是说他们是互相独立的，我抽取到身高为$x_i$的学生的概率就是

$$
P(x_i |\mu,\sigma^2)
$$

那么我抽$n$个人，得到这个特定身高集合的概率就是他们的联合分布：

$$
P(x_1,x_2,\cdots,x_n|\mu,\sigma^2)=\prod_{i=1}^nP(x_i|\mu,\sigma^2)
$$

按照前面的假设，这个概率值应该是取$n$个样本中最大的情况，所以我们通过改变分布的参数$\theta=\{\mu,\sigma^2\}$使得这个概率值取到最大值的$\hat{\theta}$就是我们**最大似然估计**求得的估计量。为了方便起见，我们定义一个**似然函数**$L(\theta)$，用这个函数来表示上面的概率值：

$$
L(\theta)=L(x_1,x_2,\cdots,x_n|\theta)=\prod_{i=1}^nP(x_i|\mu,\sigma^2)
$$

然后通过优化$\theta$最大化这个函数即可得到参数的估计：

$$
\hat\theta=argmax_\theta L(\theta)
$$

比较简单的优化可以是根据分布函数对参数求导，然后调整到极值点，由于似然函数是连乘函数，可以将它转化为**对数似然函数**便于求导：

$$
H(\theta)=lnL(\theta)=\sum_{i=1}^nP(x_i|\theta)
$$

之后的求导优化运算我就不再介绍了，因为本文的主题是EM算法，感兴趣的同学可以自行学习下最大似然估计。

![i like study]({{"/assets/blog_img/2019-07-23-EM算法.assets/20170521183913_G2ZRf.jpeg" | absolute_url}}){:height="200"}


# 3 EM算法

## 3.1 新的问题

上面MLE部分的例子是全校学生身高服从同一个正态分布，但是实际上真的是这样吗？当然不是，男生的身高和女生的身高就不属于同一个分布！明显男生身高分布的均值$\mu$要大一些。

所以，如果说全校男女生身高分布分别服从两个正态分布:

$$
N_{boy}(\mu_{boy},\sigma^2_{boy})\space and\space N_{girl}(\mu_{girl},\sigma^2_{girl})
$$

我同样在学校所有人中随机采样$n$个样本，此时如何求男生女生各自的身高分布呢？

铛铛铛铛，EM算法闪亮登场！

## 3.2 EM的引入

既然我们不知道这$n$个人中，谁是男生谁是女生，那么我们再假定存在一个分布，这个分布表示的就是，我们从总体中，随便抽一个人，这个人是男生的概率，这个分布当前是未知的。在现实中，不考虑复杂情况，这个分布应该是根据男女生人数比例确定的伯努利分布。

现在假设三个随机变量$x,y,z$分别是，男生身高、女生身高、抽出的男生还是女生。服从三个分布

$$
N_1(\mu_1,\sigma^2_1),N_2(\mu_2,\sigma^2_2),B(p)
$$

假设B表示的就是伯努利分布（具体符号我忘了，用B代替），此时要求的参数

$$
\theta=\{\mu_1,\mu_1,\sigma_1^2,\sigma_2^2\}
$$

我们随机抽取的$n$个人的身高为$h=\{h_1,h_2,\cdots,h_n\}$。

此时，如果按照前面说的最大似然估计方法：

$$
L(\theta) = \sum_{i=1}^nlog\space p(h_i|\theta)=\sum_{i=1}^nlog\sum_zp(h_i,z_i|\theta)
$$

这里的$z$就是EM算法中描述的**隐变量**，因为这是一个隐含的分布，也不是我们最终的计算输出。

之前的方法，是对似然函数求导，但是此时似然函数是**和的对数**，$log(f_1(x)+f_2(x),\cdots)$ 这种函数的求导相对复杂。此时就可以使用Jensen（琴生）不等式，其中有一条定义就是：

​	如果$f(x)$是区间$(a,b)$上的凸函数，则对任意的$x_1,x_2,\cdots,x_n\in(a,b)$，则有不等式：

$$
f\left(\frac{x_1+x_2+\cdots+x_n}{n}\right)\ge\frac{f(x_1)+f(x_2)+\cdots+f(x_n)}{n}
$$

这样我们就可以把**和的对数**变成**对数的和**，求导变简单了很多。还有一步很重要，就是引入**隐变量的分布**，方便我们进行调整，加入的方法也很简单，保持原式不变，分子分母同时乘一个数就好，这两步就能得到下面公式：

$$
\begin{aligned}
L(\theta)&=\sum_{i=1}^nlog\sum_{z_i}P(z=z_i)\frac{p(x_i,z_i,\theta)}{P(z=z_i)} \\ &\ge\sum_i\sum_{z_i}P(z=z_i)log\frac{p(x_i,z_i,\theta)}{P(z=z_i)}
\end{aligned}
$$

仔细看上面的式子，你会惊讶地发现，第二个求和部分：
$$

\sum_{z_i}P(z=z_i)log\frac{p(x_i,z_i,\theta)}{P(z=z_i)}

$$

恰好符合**期望**的形式，也就是上面式子可以看做是$log\frac{p(x_i,z_i,\theta)}{P(z=z_i)}$的期望。根据前面的式子，先化简为下面的样子：

$
L(\theta)\ge J(z,\theta)
$

因为$\theta$同时出现在不等式的左右两边，所以传统解析方法无法解决。这里只能上更*机器*的方法了，**迭代**：

​	首先，我们让$\theta$不变，然后调整$z$使得$J(z,\theta)$达到最大，与$L(\theta)$相等，这样$L(\theta)$就会有一个最大的下界；第二步，我们让$z$不变，调整$\theta$使得$L(\theta)$达到最大值。然后重复重复再重复。第一步可以叫**E步**，第二步可以叫**M步**，重复上面过程直到收敛，就是我们一直说的**EM算法​**。
